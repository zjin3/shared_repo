---
title: "Spatical Stat"
output: pdf_document
---

```{r}
library(latentnet)
library(lattice)
library(MBA)
library(geoR)
library(fields)
library(rjags)
library(R2WinBUGS)
library(R2jags)
library(mcmcse)
library(abind)
library(network)
library(MCMCpack)  # for procrustes transformation, not given in the original R file.
```



```{r}
iter <- 44
seed <- iter*6+135
set.seed(seed)
```


```{r}
### Format Data
data(emon) 
# help(emon)
# head(emon)
```


```{r}
### emon$Texas # to check what attributes the network has.
### n = 25 vertices
### get.vertex.attribute(emon$Texas, "Decision.Rank.Score")
### get "rank" attributes:
rank <- get.vertex.attribute(emon$Texas, "Decision.Rank.Score")
```


```{r}
test2 <- as.sociomatrix(emon$Texas)
# test2
# dim(test2)

### delete vertices that has missing attributes from the network:
# which(is.na(rank))
test2 <- test2[-which(is.na(rank)),]
# dim(test2)
test2 <- test2[,-which(is.na(rank))]
# dim(test2)
### 20 by 20 matrix
```



```{r}
### tranform attribute by log:
spatatt <- log(rank[-which(is.na(rank))])

test2 <- (t(test2)+test2) ### undirected connections
test2[test2>1] <- 1       ### make a network of 0 and 1

adj1 <- test2             ### the adjacent matrix
N    <- dim(adj1)[1]
```

"adj1"    is our adjacent matrix
"N"       is number of vertices
"spatatt" is the attributes



# PART I
## Two-step procedure to find appropriate covariance form-------------------------
___________________________________________________________________________________

### Step 1 : Fit latent space model independent of the spatial data

```{r}
# library(network)
# help(network)


### form a network (network object) without any attributes
net1 <- network(adj1, directed=F)     
### > net1
### > get.vertex.attribute(net1, attrname="vertax.names")
### [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
### independent of the spatial data


### Fit a Latent Space Random Graph Model:
# library(latentnet)
### a network representation in the latent space (R^2 Euclidean space)
net2 <- ergmm(net1~euclidean(d=2), tofit=c("mle"))

### give latent position Z for the N=20 vertices
coords <- net2$mle$Z
```

"coords" is the fitted latent position

```{r}
# plot(coords, xlab = "Z_1", ylab = "Z_2")
```



### Step 2 : Calculate the empirical semi-variogram over the above fitted latent space


```{r}
### Preliminary Correlations

connect   <- NULL
unconnect <- NULL

for(i in 1:(nrow(adj1)-1)){     # row except the last row
	for(j in (i+1):ncol(adj1)){   # elements to the right of diag element
		if(adj1[i,j]==1){
		  ### make a pair of the attributes of the connected pair
			connect <- rbind(connect, cbind(spatatt[i],spatatt[j]))
		}else{
		  ### make a pair of the attributes of the unconnected pair
			unconnect <- rbind(unconnect, cbind(spatatt[i],spatatt[j]))
		}
	}
}

### gather the attributes pair between connected vertices 
head(connect)
### gather the attributes pair between unconnected vertices 
head(unconnect)
```


and determine the form of the covariance as "exponential"

```{r}
### Empirical Semivariogram
# library("geoR")
vario1 <- variog(coords=coords, data=spatatt)
# vario1

### use the empirical variogram to fit a proper 
### semivariogram function gamma(.) in the exponential form
### with specified partial sill = 0.5 and range = 1:
fit    <- variofit(vario1, ini.cov.pars=c(.5,1), cov="exponential")


plot(vario1)
lines(fit)
```




# PART II
## Implement JAGS:------------------------------------------------------------
________________________________________________________________________________

### Step 1: Define the model using the BUGS language:

```{r}
### JAGS, in BUGS language

func1 <- function(){
	### Spatial part
	for(i in 1:N){
		mu[i]    <- beta
		z[i, 1:2] ~ dmnorm(mu.z[], prec.z[,]) 
		for(j in 1:N){
			M[i,j] <- sigmasq*exp(-phi*dist[i,j])
		}
	}
	Y ~ dmnorm(mu, error.prec[,])  ### Y is s(z) 
	
	### Spatial Priors
	beta                  ~ dnorm(0.0,0.0001)
	tau.prec              ~ dgamma(tausq_prior1, tausq_prior2)
	tausq                <- 1 / tau.prec
	phi                   ~ dunif(phi_lower, phi_upper)
	spat.prec             ~ dgamma(sigmasq_prior1, sigmasq_prior2)
	sigmasq              <- 1 / spat.prec
	var.all[1:N, 1:N]    <- tausq*I[1:N, 1:N] + M[1:N, 1:N]
	error.prec[1:N, 1:N] <- inverse(var.all[1:N, 1:N])
	
	### Network part
	for(i in 1:N){
		for(j in 1:N){
			dist[i,j] <- pow(pow((z[i,1] - z[j,1]), 2) + pow((z[i,2] - z[j,2]), 2), 0.5)
			p[i,j]    <- a + b*abs(Y[i]-Y[j]) - dist[i,j]
			padj[i,j] <- exp(p[i,j]) / (1+exp(p[i,j]))    ### take logit
			adj[i,j]   ~ dbern(padj[i,j])
		}
	}
	a ~ dunif(a_lower, a_upper)
	b ~ dunif(b_lower, b_upper)
}



### specify independent priors parameters
data1 <- list(adj            = adj1,      ### adjacent matrix N by N
              Y              = spatatt,   ### the observed N attributes s(z_i)
              tausq_prior1   = 2,          
              tausq_prior2   = 0.01, 
              phi_lower      = 0.1, 
              phi_upper      = 1, 
              sigmasq_prior1 = 2, 
              sigmasq_prior2 = 0.5, 
              a_lower        = -5, 
              a_upper        = 5, 
              b_lower        = -20, 
              b_upper        = 20, 
              mu.z           = c(0,0), 
              prec.z         = matrix(c(0.25,0,0,0.25), 2, 2), 
              N = N, I = diag(rep(1, N)))
```


### Step 2: Read in the model file using the "jags.model()" function. 
        This creates an object of class "jags".
```{r}
### use the fitted independent latent space model as initial value
inits1      <- list(z = as.matrix(coords))

testfile    <- file.path(tempdir(), "testfile.txt")
### library("R2WinBUGS")
### Convert R / S-PLUS function to a WinBUGS model file:
write.model(func1, testfile)  # func1 is our model
# file.show(testfile)


### create an object representing a Bayesian graphical model, 
### specified with a BUGS-language description of the prior distribution, 
### and a set of data:
jags1 <- jags.model(testfile, data1, inits=inits1)
# help(jags.model)
# jags1
```



### Step 3: Update the model using the update method for "jags" objects. 
        This constitutes a burn-in period.
```{r}
# library(rjags)
### run a Markov chain with 5000 iterations
### This works as the "burn-in" period, so the chain is not preserved
update(jags1, n.iter=5000)
```



### Step 4: Extract samples from the model object using the "coda.samples()" function. 
        This creates an object of class "mcmc.list" which can be used to 
        summarize the posterior distribution. 
        The coda package also provides convergence diagnostics to check 
        that the output is valid for analysis (see Plummer et al 2006).
```{r}
### extract random samples from the posterior distribution 
### of the parameters of a jags model:
parameters1 <- c("z", "tausq", "sigmasq", "phi", "beta", "a", "b")
jags2       <- jags.samples(jags1, parameters1, n.iter=100000)
# jags2$...
```




# PART III:
## Diagnostics-----------------------------------------------------------------
___________________________________________________________________________


```{r}
phijags     <-jags2$phi       # dim(phijags)
sigmasqjags <-jags2$sigmasq   # dim(sigmasqjags)
tausqjags   <-jags2$tausq     # dim(tausqjags)
zjags       <-jags2$z         # dim(zjags)
betajags    <-jags2$beta      # dim(betajags)
ajags       <-jags2$a         # dim(ajags)
bjags       <-jags2$b         # dim(bjags)

### dim(phijags) == dim(sigmasqjags) ... == dim(bjags) == 
### [dim_post_mean = 1,   n.iter = 100000, chain = 1]
### dim(zjags) == [20, 2, n.iter = 100000, chain = 1]

### MCMC chain of phi, sigma^2 and tau^2
samp_size_data <- cbind(phijags[1,,1], sigmasqjags[1,,1], tausqjags[1,,1])
# dim(samp_size_data)
```


### Calculate the effective sample size:

```{r}
### Effective Sample Size of a multivariate Markov chain, which is
### the size of an iid sample with the same variance as the current sample
# help(multiESS)
ess <- multiESS(samp_size_data)
ess
```




### Generate a much shorter chain if the effective sample size (ess) is small:

```{r}
# help(abind)

if(ess < 400){
	jags2a      <- jags.samples(jags1, parameters1, n.iter=5000)
	phijags     <- abind(jags2$phi,    jags2a$phi,     along=2)  # array bind
	sigmasqjags <- abind(jags2$sigmasq,jags2a$sigmasq, along=2)
	tausqjags   <- abind(jags2$tausq,  jags2a$tausq,   along=2)
	zjags       <- abind(jags2$z,      jags2a$z,       along=3)  # 3 here!
	betajags    <- abind(jags2$beta,   jags2a$beta,    along=2)
	ajags       <- abind(jags2$a,      jags2a$a,       along=2)
	bjags       <- abind(jags2$b,      jags2a$b,       along=2)
}

```



### Store the posterior estimators AND the Markov chains for all parameters in a list:

```{r}
# store the Markov chain for all parameters in a list:

jagsfinal <- list(phi     = phijags, 
                  sigmasq = sigmasqjags, 
                  tausq   = tausqjags, 
                  z       = zjags, 
                  beta    = betajags, 
                  a       = ajags, 
                  b       = bjags)
```

"jagsfinal" stores the final posterior means and Markov chains.


```{r}
# subtrating the 1st (only) Markov chain for each parameter:

phijags     <- jagsfinal$phi[,,1]  
sigmasqjags <- jagsfinal$sigmasq[,,1] 
tausqjags   <- jagsfinal$tausq[,,1]
zjags       <- jagsfinal$z[,,,1] 
betajags    <- jagsfinal$beta[,,1]
ajags       <- jagsfinal$a[,,1]
bjags       <- jagsfinal$b[,,1] 
```

"<para>jags" stores only the Markov chains.




### Procrustes transformations on locations Z

```{r}
### Procrustes transformations on locations

### generate an empty chain:
zjagsnew <- array(NA, dim = dim(zjags))
# dim(zjags)

### dim(zjags)[3] is the number of iterations
### for each mcmc iteration, do the Procrustes transformations:
### recall "coords" is the independent latent space model's fitted location.
# library(MCMCpack)

for(i in 1:dim(zjags)[3]){
	zjagsnew[,,i] <- procrustes(zjags[,,i], coords, translation=T,dilation=F)$X.new
}


# zjagsnew[,,1:3]
# dim(zjagsnew)    ### = [20,2,100000] == dim(zjags)
```

"zjagsnew" stores the Procrustes transformed locations Z.




### Composite sampling:

```{r}
### Composition sampling to recover the spatial effect w(z_i)
### which is a Gaussian process that depends on sigma^2 and phi

# generate an empty array to store???
# dim(zjagsnew) = [20, 2, 100000]
mat <- array(NA, dim = c(dim(zjagsnew)[1], dim(zjagsnew)[1], dim(zjagsnew)[3]) )
# dim(mat)     ### = [20, 20, 100000]

for(i in 1:dim(zjagsnew)[3]){        # for each iteration
  ### calculate the distance between the rows of a matrix M by N, 
  ### return a lower triangular matrix (M-1) by (M-1) matrix (due to symmetry);
  ### sometimes return M by M matrix with diagonal == 0.
  ### e.g. 4 by 2 matris, has row1, row2, row3.
  ### dist(matrix) first  line 0.0
  ###              second line d(row2, row1), 0.0
  ###              third  line d(row3, row2), d(row3, row1), 0.0
  ###              forth  line d(row4, row3), d(row4, row2), d(row4, row1), 0.0
  ### now calculate in each iteration the distance matrix between z_i and z_j:
	temp1    <- dist(zjagsnew[,,i])    
	mat[,,i] <- as.matrix(temp1)
}


# dim(mat) ### = [20, 20, 100000]
```

"mat" is an array, where each element is a matrix that stores (for each iteration)
the distance between the latent social position z_i and z_j.


#### Now for each iteration, sample the Gaussian process of the spatial effect w(z_i):

Code is inconsistent with the formular in the paper and confusing?????
```{r}
W_samp <- matrix(NA, nrow = dim(zjagsnew)[3], ncol = dim(zjagsnew)[1])
# dim(W_samp)    ### = [100000, 20]

for(i in 1:dim(zjags)[3]){     # for each iteration:
	var1       <- sigmasqjags[i]*exp(-phijags[i]*mat[,,i]) + tausqjags[i] * diag(1, dim(zjagsnew)[1])
	### var 1 is a N by N covariance matrix for the attribute s(z), 
	### note that mat[,,i] is the distance matrix for the N by 1 vector z, and 
	### dim(zjagsnew) = [20, 2, 100000]
	
	var2       <- tausqjags[i] * diag(1, dim(zjagsnew)[1])
	### var2 is the second part in var1, 
	### it is the variance matrix for the random error epsilon
	
	var3       <- solve( solve(var1) + (dim(zjagsnew)[1]) * solve(var2) ) # ??????????????????
	### see Apendix A for calculation derivation.
	### help(solve), here "solve" is used as finding "inverse" matrix.
	### dim(zjagsnew)[1] = 20
	
	mean1      <- var3 %*% (dim(zjagsnew)[1] * solve(var2) %*% matrix(spatatt - betajags[i]) )
	# wrong: W_samp[i,] <- rmvnorm(1, mean = mean1, sigma = var3)
	W_samp[i,] <- mvrnorm(1, mu = mean1, Sigma = var3)
}

```


My calculation for sampling W:
```{r}
my_W_samp <- matrix(NA, nrow = dim(zjagsnew)[3], ncol = dim(zjagsnew)[1])


for(i in 1:dim(zjags)[3]){     # for each iteration:
	var1       <- sigmasqjags[i]*exp(-phijags[i]*mat[,,i])
	var2       <- tausqjags[i] * diag(1, dim(zjagsnew)[1])
	var        <- var1 - var1 %*% solve(var1 + var2) %*% var1
	
	mean       <- var1 %*% solve(var1 + var2) %*% matrix(spatatt - betajags[i])
	my_W_samp[i,] <- mvrnorm(1, mu = mean, Sigma = var)
}
```


The posterior mean:
Why not use jagsfinal$...[1] ......
```{r}
### Results
phimean     <-  mean(phijags)                # the same as jagsfinal$phi
sigmasqmean <-  mean(sigmasqjags)            # jagsfinal$sigmasq
tausqmean   <-  mean(tausqjags)              # jagsfinal$tausq
zmean       <-  apply(zjagsnew,c(1,2),mean)  # jagsfinal$z
Wmean       <-  apply(W_samp,2,mean)         
betamean    <-  mean(betajags)               # jagsfinal$beta
amean       <-  mean(ajags)                  # jagsfinal$a
bmean       <-  mean(bjags)                  # jagsfinal$b

```



```{r}
# Extra:
my_Wmean = apply(my_W_samp,2,mean)
cbind(my_Wmean, Wmean, Wmean - my_Wmean)             # difference is not very obvious
cbind( apply(my_W_samp,2,var), apply(W_samp,2,var) )
```
"...mean" stores the posterior mean.


Calculate quantile:
```{r}
phiq      <- quantile(phijags, c(0.025, 0.975))
sigmasqq  <- quantile(sigmasqjags, c(0.025, 0.975))
tausqq    <- quantile(tausqjags, c(0.025, 0.975)) 
betaq     <- quantile(betajags, c(0.025, 0.975)) 
aq        <- quantile(ajags, c(0.025, 0.975)) 
bq        <- quantile(bjags, c(0.025, 0.975)) 

```

"...q" stores the quantiles.



Collect posterior mean and the quantiles in a table:
```{r}
tab <- cbind(rbind(phimean, 
                   sigmasqmean, 
                   tausqmean, 
                   betamean, 
                   amean, 
                   bmean), 
             rbind(phiq, sigmasqq, tausqq, betaq, aq, bq))
tab

```




```{r}
# Surface approximation from bivariate scattered data 
surf  <- mba.surf(cbind(zmean, Wmean), no.X = 100, no.Y = 100, extend = F)$xyz.est
# ? mba.surf
# gives x coordinates, y coordinates (determined by the n.Y), 
# and the no.X by no.Y matrix estimated Wmean which we care about

z.lim <- range(surf$z, na.rm=TRUE)
# gives the largest and the smallest value of the estimated Wmean
# why there are so many NA ??????

# color scale plot based on a grid of quadrilaterals.
image.plot(surf, xaxs = "r", yaxs = "r", zlim = z.lim, main = "Mean spatial effects")
# range(surf$x)   ### corresponds to the range in the x-asix
# range(surf$y)   ### corresponds to the range in the y-asix
# ? image.plot
# x<- 1:10
# y<- 1:15
# z<- outer( x,y,"+") 
# the plot here is not rectangle as in the above example,
# this is because there are many NA in surf$z 
# (which corresponds to a large area of (surf$x, surf$y). )
# this is the limitation of the method used in mba.surf() function.

points(zmean)

# Plot the fitted network in the plot:

Num <- dim(zmean)[1]   # just the number of vertices

for(i in 1:(Num - 1)){
	for(j in (i+1):Num){
		if(adj1[i,j]==1){
		  # Draw line segments between pairs of points:
			segments(zmean[i,1], zmean[i,2], zmean[j,1], zmean[j,2])
		}
	}
}

```


Extra:

```{r}
which.max.matrix(surf$z)    # check in the above plot, it is where the largest estimate takes place
minus_z = -surf$z
which.max.matrix(minus_z)   # where the smallest estimate takes place
```




### Draw the MCMC trace plots:

```{r}
par(mfrow=c(2,3))

plot(phijags,     type = "l", xlab = "Iteration", ylab = expression(phi))
plot(sigmasqjags, type = "l", xlab = "Iteration", ylab = expression(sigma^2))
plot(tausqjags,   type = "l", xlab = "Iteration", ylab = expression(tau^2))
plot(betajags,    type = "l", xlab = "Iteration", ylab = expression(beta))
plot(ajags,       type = "l", xlab = "Iteration", ylab = expression(a))
plot(bjags,       type = "l", xlab = "Iteration", ylab = expression(b))
```













~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

my digression: 
```{r}
library(sna)
g<-matrix(1,nc=2,nr=2)
gplot(g)
gplot(rgraph(5)) 
```


my digression:
```{r}
library(network)
data(emon)
# help(emon)


# Number of vertices
n <- ncol(as.sociomatrix(emon[[4]]))
# emon$MtSi
# as.sociomatrix(emon$MtSi)
 
colorn <- rainbow(n, start=.7, end=.1)
 
vname <- get.vertex.attribute(emon[[4]],attrname="vertex.names")
 
plot.network(emon[[4]], usearrows=FALSE, displayisolates=FALSE, vertex.col=colorn, main="Mt. Si SAR EMON")

legend("topleft", legend=vname, col=colorn, pch=19,bty="n",cex=.5)

```











